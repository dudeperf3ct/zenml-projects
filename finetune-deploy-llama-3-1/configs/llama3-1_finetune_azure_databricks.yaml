# Apache Software License 2.0
# 
# Copyright (c) ZenML GmbH 2024. All rights reserved.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
# http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# 

model:
  name: llama-3-1-ai-doctor
  description: "Fine-tune `llama-3.1`."
  tags:
    - llm
    - peft
    - llama-3.1
    - remote
    - ai-medical-chatbot
  version: 3 epochs

settings:
  docker: 
    parent_image: pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime
    requirements: requirements.txt
    python_package_installer: uv
    python_package_installer_args:
      system: null
    apt_packages: 
      - openssh-server
      - git
    environment:
      PJRT_DEVICE: CUDA
      USE_TORCH_XLA: "false"
      MKL_SERVICE_FORCE_INTEL: "1"
  orchestrator.vm_azure:
    instance_type: Standard_NC24ads_A100_v4
    region: westeurope
    idle_minutes_to_autostop: 60
    down: True
    stream_logs: True
    #retry_until_up: True
    docker_run_args: 
      - "--gpus=all"
  orchestrator.databricks:
    spark_version : 15.3.x-gpu-ml-scala2.12
    node_type_id : Standard_NC24ads_A100_v4
    autoscale:
      - 0
      - 1
    

parameters:
  base_model_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  load_in_4bit: True
  system_prompt: |
    You are an AI Medical Assistant trained on a vast dataset of health information. Please be thorough and provide an informative answer. If you don't know the answer to a specific medical inquiry, advise seeking professional help.
    

steps:
  prepare_data:
    parameters:
      dataset_name: ruslanmv/ai-medical-chatbot

  finetune:
    parameters:
      eval_steps: 100
      epochs: 2
      per_device_train_batch_size: 32
    
  promote:
    parameters:
      metric: rouge2
      target_stage: staging

  merge_and_log_model:
    parameters:
      model_name: llama-3-1-ai-doctor

  opitmize_model:
    settings:
      docker:
        build_config:
          build_options:
            platform: linux/amd64
        parent_image: ghcr.io/ggerganov/llama.cpp:full-cuda
        requirements: requirements.txt
        python_package_installer: uv
        python_package_installer_args:
          system: null
        apt_packages: 
          - openssh-server
          - git
        environment:
          PJRT_DEVICE: CUDA
          USE_TORCH_XLA: "false"
          MKL_SERVICE_FORCE_INTEL: "1"
          LLAMA_CUDA: "1" 
          LLAMA_DEBUG: "1"
          LLAMA_CURL: "1"
    parameters:
      model_name: llama-3-1-ai-doctor