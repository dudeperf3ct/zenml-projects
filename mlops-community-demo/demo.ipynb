{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2;36mActive repository stack set to: \u001b[0m\u001b[2;32m'default'\u001b[0m.\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Setting the repository active stack to 'default'...t'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml stack set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mmy_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malex.ext@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL for Pipeline Run: \u001b[0m\u001b[34mhttps://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/5ce32934-0a24-4121-a396-e46b053b6fce\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mmy_step\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmy_step\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m1.754s\u001b[1;35m.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineRunResponse(body=PipelineRunResponseBody(created=datetime.datetime(2024, 9, 11, 19, 7, 52), updated=datetime.datetime(2024, 9, 11, 19, 7, 54), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2024, 2, 8, 8, 8, 21), updated=datetime.datetime(2024, 9, 11, 18, 54, 43), active=True, activation_token=None, full_name='Alex Strick van Linschoten', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('f4982973-1f26-41d3-a3a1-e2000f5427cb'), permission_denied=False, name='alex.ext@zenml.io'), status=<ExecutionStatus.COMPLETED: 'completed'>, stack=StackResponse(body=StackResponseBody(created=datetime.datetime(2023, 11, 30, 9, 39, 29), updated=datetime.datetime(2023, 11, 30, 9, 39, 29), user=None), metadata=None, resources=None, id=UUID('a4cd4161-6ee5-411c-8adf-559ac084ceb5'), permission_denied=False, name='default'), pipeline=PipelineResponse(body=PipelineResponseBody(created=datetime.datetime(2024, 6, 13, 16, 10, 35), updated=datetime.datetime(2024, 6, 13, 16, 10, 35), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2023, 11, 16, 16, 5, 33), updated=datetime.datetime(2024, 9, 4, 12, 1, 47), active=True, activation_token=None, full_name='Andrei', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('c915043d-706c-4885-9263-783cae8dad20'), permission_denied=False, name='andrei@zenml.io'), latest_run_id=UUID('5ce32934-0a24-4121-a396-e46b053b6fce'), latest_run_status=<ExecutionStatus.COMPLETED: 'completed'>), metadata=None, resources=None, id=UUID('017ce2b5-34ac-4dbf-9f63-d9c94e4c5f9e'), permission_denied=False, name='my_pipeline'), build=None, schedule=None, code_reference=None, deployment_id=UUID('aec0b5a0-0adb-474c-a786-84a2e840a403'), trigger_execution=None, model_version_id=None), metadata=PipelineRunResponseMetadata(workspace=WorkspaceResponse(body=WorkspaceResponseBody(created=datetime.datetime(2023, 10, 23, 15, 34, 47), updated=datetime.datetime(2023, 10, 23, 15, 34, 47)), metadata=None, resources=None, id=UUID('f3a544f2-afb5-4672-934a-7a465c66201c'), permission_denied=False, name='default'), run_metadata={}, steps={'my_step': StepRunResponse(body=StepRunResponseBody(created=datetime.datetime(2024, 9, 11, 19, 7, 54), updated=datetime.datetime(2024, 9, 11, 19, 7, 54), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2024, 2, 8, 8, 8, 21), updated=datetime.datetime(2024, 9, 11, 18, 54, 43), active=True, activation_token=None, full_name='Alex Strick van Linschoten', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('f4982973-1f26-41d3-a3a1-e2000f5427cb'), permission_denied=False, name='alex.ext@zenml.io'), status=<ExecutionStatus.CACHED: 'cached'>, inputs={}, outputs={}, model_version_id=None), metadata=None, resources=None, id=UUID('d548227a-a6ad-4ad7-81b7-0b84a2df2f81'), permission_denied=False, name='my_step')}, config=PipelineConfiguration(enable_cache=None, enable_artifact_metadata=None, enable_artifact_visualization=None, enable_step_logs=None, settings={}, extra={}, failure_hook_source=None, success_hook_source=None, model=None, parameters=None, retry=None, name='my_pipeline'), start_time=datetime.datetime(2024, 9, 11, 19, 7, 52), end_time=datetime.datetime(2024, 9, 11, 19, 7, 54), client_environment={'environment': 'notebook', 'os': 'mac', 'mac_version': '14.6.1', 'python_version': '3.11.9'}, orchestrator_environment={'environment': 'notebook', 'os': 'mac', 'mac_version': '14.6.1', 'python_version': '3.11.9'}, orchestrator_run_id='4ad7bea2-f27e-4e3a-8944-01cd995ef4d7', code_path=None, template_id=None), resources=PipelineRunResponseResources(model_version=None, tags=[]), id=UUID('5ce32934-0a24-4121-a396-e46b053b6fce'), permission_denied=False, name='my_pipeline-2024_09_11-19_07_52_021504')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zenml import pipeline, step\n",
    "\n",
    "@step\n",
    "def my_step():\n",
    "    print(\"Hello world!\")\n",
    "\n",
    "@pipeline\n",
    "def my_pipeline():\n",
    "    my_step()\n",
    "\n",
    "my_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mRunning single step pipeline to execute step \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malex.ext@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL for Pipeline Run: \u001b[0m\u001b[34mhttps://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/9847438a-7ee2-44f0-a1a1-a2fc2d90f101\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m has started.\u001b[0m\n",
      "This is another step!\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m has finished in \u001b[0m\u001b[1;36m0.740s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36msome_other_step\u001b[1;35m completed successfully.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m1.804s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "@step\n",
    "def some_other_step():\n",
    "    print(\"This is another step!\")\n",
    "\n",
    "some_other_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2;36mActive repository stack set to: \u001b[0m\u001b[2;32m'az_k8s_pigeon'\u001b[0m.\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Setting the repository active stack to 'az_k8s_pigeon'...n'...\u001b[0m\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!zenml stack set az_k8s_pigeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.kubernetes.flavors import (\n",
    "    KubernetesOrchestratorSettings,\n",
    ")\n",
    "\n",
    "MNT_PATH = \"/mnt/data\"\n",
    "\n",
    "kubernetes_settings = KubernetesOrchestratorSettings(\n",
    "    pod_settings={\n",
    "        \"affinity\": {\n",
    "            \"nodeAffinity\": {\n",
    "                \"requiredDuringSchedulingIgnoredDuringExecution\": {\n",
    "                    \"nodeSelectorTerms\": [\n",
    "                        {\n",
    "                            \"matchExpressions\": [\n",
    "                                {\n",
    "                                    \"key\": \"zenml.io/gpu\",\n",
    "                                    \"operator\": \"In\",\n",
    "                                    \"values\": [\"yes\"],\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"volumes\": [\n",
    "            {\n",
    "                \"name\": \"data-volume\",\n",
    "                \"persistentVolumeClaim\": {\"claimName\": \"pvc-managed-premium\"},\n",
    "            }\n",
    "        ],\n",
    "        \"volume_mounts\": [{\"name\": \"data-volume\", \"mountPath\": MNT_PATH}],\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zenml.config import DockerSettings\n",
    "\n",
    "docker_settings = DockerSettings(\n",
    "    parent_image=\"pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime\",\n",
    "    environment={\n",
    "        \"PJRT_DEVICE\": \"CUDA\",\n",
    "        \"USE_TORCH_XLA\": \"false\",\n",
    "        \"MKL_SERVICE_FORCE_INTEL\": 1,\n",
    "        \"HF_TOKEN\": os.environ[\"HF_TOKEN\"],\n",
    "        \"HF_HOME\": MNT_PATH,\n",
    "    },\n",
    "    python_package_installer=\"uv\",\n",
    "    requirements=\"requirements.txt\",\n",
    "    python_package_installer_args={\n",
    "        \"system\": None,\n",
    "    },\n",
    "    apt_packages=[\"git\", \"ffmpeg\"],\n",
    "    # prevent_build_reuse=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mk8s_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUploading notebook code...\u001b[0m\n",
      "\u001b[1;35mUpload finished.\u001b[0m\n",
      "\u001b[1;35mUnable to find a build to reuse. A previous build can be reused when the following conditions are met:\n",
      "  * The existing build was created for the same stack, ZenML version and Python version\n",
      "  * The stack contains a container registry\n",
      "  * The Docker settings of the pipeline and all its steps are the same as for the existing build.\u001b[0m\n",
      "\u001b[1;35mBuilding Docker image(s) for pipeline \u001b[0m\u001b[1;36mk8s_pipeline\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mBuilding Docker image \u001b[0m\u001b[1;36mdemozenmlcontainerregistry.azurecr.io/zenml:k8s_pipeline-orchestrator\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35m- Including stack requirements: \u001b[0m\u001b[1;36madlfs>=2021.10.0\u001b[1;35m, \u001b[0m\u001b[1;36mazure-ai-ml==1.18.0\u001b[1;35m, \u001b[0m\u001b[1;36mazure-identity\u001b[1;35m, \u001b[0m\u001b[1;36mazure-keyvault-keys\u001b[1;35m, \u001b[0m\u001b[1;36mazure-keyvault-secrets\u001b[1;35m, \u001b[0m\u001b[1;36mazure-mgmt-containerservice>=20.0.0\u001b[1;35m, \u001b[0m\u001b[1;36mazure-storage-blob==12.17.0\u001b[1;35m, \u001b[0m\u001b[1;36mazureml-core==1.56.0\u001b[1;35m, \u001b[0m\u001b[1;36mipywidgets>=8.0.0\u001b[1;35m, \u001b[0m\u001b[1;36mkubernetes\u001b[1;35m, \u001b[0m\u001b[1;36mkubernetes>=21.7,<26\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m- Including user-defined requirements from file \u001b[0m\u001b[1;36m/Users/strickvl/coding/zenml/repos/zenml-projects/mlops-community-demo/requirements.txt\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mIncluding apt packages: \u001b[0m\u001b[1;36mgit\u001b[1;35m, \u001b[0m\u001b[1;36mffmpeg\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mStep 1/18 : FROM pytorch/pytorch:2.2.2-cuda11.8-cudnn8-runtime\u001b[0m\n",
      "\u001b[1;35mStep 2/18 : WORKDIR /app\u001b[0m\n",
      "\u001b[1;35mStep 3/18 : ENV ZENML_LOGGING_COLORS_DISABLED=False\u001b[0m\n",
      "\u001b[1;35mStep 4/18 : ENV PJRT_DEVICE=CUDA\u001b[0m\n",
      "\u001b[1;35mStep 5/18 : ENV USE_TORCH_XLA=false\u001b[0m\n",
      "\u001b[1;35mStep 6/18 : ENV MKL_SERVICE_FORCE_INTEL=1\u001b[0m\n",
      "\u001b[1;35mStep 7/18 : ENV HF_TOKEN=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\u001b[0m\n",
      "\u001b[1;35mStep 8/18 : ENV HF_HOME=/mnt/data\u001b[0m\n",
      "\u001b[1;35mStep 9/18 : RUN apt-get update && apt-get install -y --no-install-recommends 'git' 'ffmpeg'\u001b[0m\n",
      "\u001b[1;35mStep 10/18 : RUN pip install uv\u001b[0m\n",
      "\u001b[1;35mStep 11/18 : COPY .zenml_stack_integration_requirements .\u001b[0m\n",
      "\u001b[1;35mStep 12/18 : RUN uv pip install --no-cache-dir --system -r .zenml_stack_integration_requirements\u001b[0m\n",
      "\u001b[1;35mStep 13/18 : COPY .zenml_user_requirements .\u001b[0m\n",
      "\u001b[1;35mStep 14/18 : RUN uv pip install --no-cache-dir --system -r .zenml_user_requirements\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from zenml import pipeline, step\n",
    "\n",
    "@step(settings={\"orchestrator.kubernetes\": kubernetes_settings})\n",
    "def k8s_step():\n",
    "    print(\"Training model...\")\n",
    "\n",
    "@pipeline(settings={\"docker\": docker_settings})\n",
    "def k8s_pipeline():\n",
    "    k8s_step()\n",
    "\n",
    "k8s_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-community",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
