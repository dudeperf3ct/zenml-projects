{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Personalized AI with Flux.1 and DreamBooth\n",
    "\n",
    "Picture this: thousands of users creating their own personalized AI models with just a few clicks. Pretty dope, right? In this notebook, we're gonna dive headfirst into building a kickass system to make that wild idea a reality using Flux.1 and DreamBooth.\n",
    "\n",
    "We'll geek out over the nuts and bolts of a bleeding-edge system that juggles thousands of personalized Flux.1 model finetunings like a boss. Along the way, we'll tackle the gnarly technical challenges of scaling GenAI services and show you how to harness the power of open-source tools like ZenML to construct beastly pipelines for mass AI personalization on your cloud of choice.\n",
    "\n",
    "This notebook is packed with all sorts of goodies, including:\n",
    "\n",
    "- Slick techniques for deploying on any cloud you throw at it \n",
    "- Crafty strategies for keeping the AI watchdogs at bay (looking at you, EU AI Act)\n",
    "- Clever ways to track your data and models so you always know what's what\n",
    "- Mad skills for versioning your models, data, and code like a pro\n",
    "- Sorcery for making your distributed setups behave consistently\n",
    "- Insider knowledge on leveraging open-source tools like ZenML to build GenAI systems that can take a beating\n",
    "\n",
    "By the time you're done with this notebook, you'll be a certified wizard at whipping up scalable, personalized AI systems. The code samples and explanations will give you the superpowers you need to bring these ideas to life in your own mad scientist projects, whether you're a seasoned ML mastermind looking to crank your systems up to 11 or a curious tinkerer dipping your toes into the wild world of large-scale AI deployments.\n",
    "\n",
    "Buckle up and get ready to have your mind blown as we embark on this epic quest to bend massive, personalized AI to your will!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some boilerplate to get us started!\n",
    "\n",
    "This section sets up the necessary configurations and imports for the project. It defines two dataclasses, `SharedConfig` and `TrainConfig`, which hold various configuration parameters for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from accelerate.utils import write_basic_config\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "from zenml import pipeline, step\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SharedConfig:\n",
    "    \"\"\"Configuration information shared across project components.\"\"\"\n",
    "\n",
    "    # The instance name is the \"proper noun\" we're teaching the model\n",
    "    instance_name: str = \"blupus cat\"\n",
    "    # That proper noun is usually a member of some class (person, bird),\n",
    "    # and sharing that information with the model helps it generalize better.\n",
    "    class_name: str = \"ginger cat\"\n",
    "    # identifier for pretrained models on Hugging Face\n",
    "    model_name: str = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig(SharedConfig):\n",
    "    \"\"\"Configuration for the finetuning step.\"\"\"\n",
    "\n",
    "    # training prompt looks like `{PREFIX} {INSTANCE_NAME} the {CLASS_NAME} {POSTFIX}`\n",
    "    prefix: str = \"a photo of\"\n",
    "    postfix: str = \"\"\n",
    "\n",
    "    # locator for directory containing images of target instance\n",
    "    instance_example_dir: str = str(\n",
    "        Path(__file__).parent / \"instance_examples\"\n",
    "    )\n",
    "\n",
    "    # Hyperparameters/constants from the huggingface training example\n",
    "    resolution: int = 512\n",
    "    train_batch_size: int = 3\n",
    "    rank: int = 16  # lora rank\n",
    "    gradient_accumulation_steps: int = 1\n",
    "    learning_rate: float = 4e-4\n",
    "    lr_scheduler: str = \"constant\"\n",
    "    lr_warmup_steps: int = 0\n",
    "    max_train_steps: int = 500\n",
    "    checkpointing_steps: int = 1000\n",
    "    seed: int = 117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our data\n",
    "\n",
    "Here, we define a function `load_image_paths` to load the paths of all image files in a given directory. The `load_data` step function uses this to load the paths of the instance example images, which will be used for training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paths to all of the images in a specific directory\n",
    "def load_image_paths(image_dir: Path) -> List[Path]:\n",
    "    return list(image_dir.glob(\"*.png\"))\n",
    "\n",
    "\n",
    "@step\n",
    "def load_data() -> List[Path]:\n",
    "    # Load image paths from the instance_example_dir\n",
    "    instance_example_paths: List[Path] = load_image_paths(\n",
    "        Path(TrainConfig().instance_example_dir)\n",
    "    )\n",
    "    return instance_example_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "This section contains the `train_model` step function, which handles the actual training process. It sets up the training environment, defines the training prompt, and executes the DreamBooth training script as a subprocess using the specified configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(step_operator=\"k8s_step_operator\")\n",
    "def train_model(instance_example_urls: List[str]):\n",
    "    config = TrainConfig()\n",
    "\n",
    "    # load data locally\n",
    "    img_path = load_images(instance_example_urls)\n",
    "\n",
    "    # set up hugging face accelerate library for fast training\n",
    "    write_basic_config(mixed_precision=\"bf16\")\n",
    "\n",
    "    # define the training prompt\n",
    "    instance_phrase = f\"{config.instance_name} the {config.class_name}\"\n",
    "    prompt = f\"{config.prefix} {instance_phrase} {config.postfix}\".strip()\n",
    "\n",
    "    # the model training is packaged as a script, so we have to execute it as a subprocess, which adds some boilerplate\n",
    "    def _exec_subprocess(cmd: List[str]):\n",
    "        \"\"\"Executes subprocess and prints log to terminal while subprocess is running.\"\"\"\n",
    "        process = subprocess.Popen(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "        )\n",
    "        with process.stdout as pipe:\n",
    "            for line in iter(pipe.readline, b\"\"):\n",
    "                line_str = line.decode()\n",
    "                print(f\"{line_str}\", end=\"\")\n",
    "\n",
    "        if exitcode := process.wait() != 0:\n",
    "            raise subprocess.CalledProcessError(exitcode, \"\\n\".join(cmd))\n",
    "\n",
    "    # run training -- see huggingface accelerate docs for details\n",
    "    print(\"launching dreambooth training script\")\n",
    "    _exec_subprocess(\n",
    "        [\n",
    "            \"accelerate\",\n",
    "            \"launch\",\n",
    "            \"/home/strickvl/coding/zenml-projects/flux-dreambooth/diffusers/examples/dreambooth/train_dreambooth.py\",\n",
    "            \"--mixed_precision=bf16\",  # half-precision floats most of the time for faster training\n",
    "            f\"--pretrained_model_name_or_path={config.model_name}\",\n",
    "            f\"--instance_data_dir={img_path}\",\n",
    "            f\"--output_dir=./model\",\n",
    "            f\"--instance_prompt={prompt}\",\n",
    "            f\"--resolution={config.resolution}\",\n",
    "            f\"--train_batch_size={config.train_batch_size}\",\n",
    "            f\"--gradient_accumulation_steps={config.gradient_accumulation_steps}\",\n",
    "            f\"--learning_rate={config.learning_rate}\",\n",
    "            f\"--lr_scheduler={config.lr_scheduler}\",\n",
    "            f\"--lr_warmup_steps={config.lr_warmup_steps}\",\n",
    "            f\"--max_train_steps={config.max_train_steps}\",\n",
    "            f\"--checkpointing_steps={config.checkpointing_steps}\",\n",
    "            f\"--seed={config.seed}\",  # increased reproducibility by seeding the RNG\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch inference\n",
    "\n",
    "After training the model, this section defines the `batch_inference` step function. It loads the trained model and generates a batch of images using a list of prompts related to the instance (in this case, a cat named \"blupus\" in various Parisian scenarios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step(step_operator=\"k8s_step_operator\")\n",
    "def batch_inference(model_path: str):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_path, torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    prompts = [\n",
    "        \"A photo of blupus cat wearing a beret in front of the Eiffel Tower\",\n",
    "        \"A portrait photo of blupus cat on a busy Paris street\",\n",
    "        \"A photo of blupus cat sitting at a Parisian cafe\",\n",
    "        \"A photo of blupus cat playing with a toy Eiffel Tower\",\n",
    "        \"A photo of blupus cat sleeping on a French balcony\",\n",
    "        \"A photo of blupus cat chasing pigeons in the Jardin des Tuileries\",\n",
    "        \"A photo of blupus cat perched on a windowsill overlooking the Paris skyline\",\n",
    "        \"A photo of blupus cat curled up on a cozy Parisian apartment sofa\",\n",
    "        \"A photo of blupus cat playing with a red laser pointer in the Louvre\",\n",
    "        \"A photo of blupus cat sitting in a vintage Louis Vuitton trunk\",\n",
    "        \"A photo of blupus cat wearing a tiny beret and a French flag bow tie\",\n",
    "        \"A photo of blupus cat stretching on a yoga mat with the Arc de Triomphe in the background\",\n",
    "        \"A photo of blupus cat peeking out from under a Parisian hotel bed\",\n",
    "        \"A photo of blupus cat chasing its tail on the Champs-Élysées\",\n",
    "        \"A photo of blupus cat sitting next to a fishbowl in a Parisian pet shop window\",\n",
    "    ]\n",
    "\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        image = pipe(\n",
    "            prompt, num_inference_steps=70, guidance_scale=7.5\n",
    "        ).images[0]\n",
    "        image.save(f\"blupus_{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting the dots!\n",
    "\n",
    "Now we can connect the dots and create our pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def dreambooth_pipeline():\n",
    "    data = load_data()\n",
    "    train_model(data)\n",
    "    batch_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreambooth_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
